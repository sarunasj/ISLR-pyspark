{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Resampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> Define Spark session and SQLContext \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('resampling_methods').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, StringIndexer, OneHotEncoder, PolynomialExpansion\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Lab: Cross-Validation and the Boostrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *5.3.1. The Validation Set Approach*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auto dataset:\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|year|origin|                name|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0|  3504|        12.0|  70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0|  3693|        11.5|  70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0|  3436|        11.0|  70|     1|  plymouth satellite|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      "Data types:\n",
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cylinders: integer (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- horsepower: double (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- origin: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "Models' Mean Squared Error (MSE) on train data 18.038\n",
      "Models' Mean Squared Error (MSE) on test data 21.646\n"
     ]
    }
   ],
   "source": [
    "# -> Load Auto dataset\n",
    "\n",
    "Auto = spark.read.csv('data/Auto.csv',header=True,inferSchema=True)\n",
    "Auto = Auto.withColumn('horsepower', F.col('horsepower').cast(DoubleType()))\n",
    "Auto = Auto.na.drop()\n",
    "\n",
    "print('\\nAuto dataset:'); Auto.show(3)\n",
    "print('\\nData types:'); Auto.printSchema()\n",
    "\n",
    "# -> Prepare data\n",
    "\n",
    "data = Auto.withColumn('horsepower_power_2', F.pow(F.col('horsepower'),2))\n",
    "data = utils.prepare_data(data,\n",
    "                          labelCol = 'mpg',\n",
    "                          label_is_categorical = False,\n",
    "                          categoricalCols = [],\n",
    "                          continuousCols = ['horsepower', 'horsepower_power_2'])\n",
    "\n",
    "# -> Create train and test samples\n",
    "\n",
    "train, test = data.randomSplit([0.7,.3], seed=42)\n",
    "\n",
    "# -> Describe the model:\n",
    "\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol='label')\n",
    "\n",
    "# -> Fit the model:\n",
    "\n",
    "model_fit = model.fit(train)\n",
    "\n",
    "# -> Estimate models' MSE for train and test samples:\n",
    "\n",
    "train_predictions = model_fit.transform(train)\n",
    "test_predictions = model_fit.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"mpg\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "train_mse = evaluator.evaluate(train_predictions)\n",
    "test_mse = evaluator.evaluate(test_predictions)\n",
    "\n",
    "print(\"Models' Mean Squared Error (MSE) on train data {:.3f}\".format(train_mse))\n",
    "print(\"Models' Mean Squared Error (MSE) on test data {:.3f}\".format(test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *5.3.3 k-Fold Cross-Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE average = 24.231\n"
     ]
    }
   ],
   "source": [
    "# -> Prepare data:\n",
    "\n",
    "data = utils.prepare_data(df=Auto,\n",
    "                    labelCol='mpg',\n",
    "                    label_is_categorical=False,\n",
    "                    categoricalCols=[],\n",
    "                    continuousCols=['horsepower'])\n",
    "\n",
    "# -> Describe the model:\n",
    "\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol='label')\n",
    "\n",
    "# -> Estimate K=3 cross validation MSE:\n",
    "\n",
    "modelEvaluator=RegressionEvaluator(metricName=\"mse\")\n",
    "\n",
    "pipeline = Pipeline(stages=[model])\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "cv = CrossValidator(estimator=model,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=3,\n",
    "                          seed=42)\n",
    "cvModel = cv.fit(data)\n",
    "print('CV MSE average = {:.3f}'.format(cvModel.avgMetrics[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *5.3.4 The Bootstrap*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------------+\n",
      "| id|                  X|                 Y|\n",
      "+---+-------------------+------------------+\n",
      "|  0|0.41371264720975787|0.5888539012978773|\n",
      "|  1| 0.7311719281896606|0.8645537008427937|\n",
      "|  2| 0.9031701155118229|1.2524569684217643|\n",
      "|  3|0.09430205113458567|-2.573636861034734|\n",
      "|  4|0.38340505276222947|0.5469737451926588|\n",
      "+---+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "estimated bootstrap lower and upper quantiles = [0.89564129 0.92415818]\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "\n",
    "from pyspark.sql.functions import rand, randn\n",
    "Portfolio = spark.createDataFrame(pd.DataFrame(np.arange(0, 1000, 1), columns=['id']))\n",
    "Portfolio = Portfolio.select(\"id\", \n",
    "               F.rand(seed=10).alias(\"X\"), \n",
    "               F.randn(seed=27).alias(\"Y\"))\n",
    "Portfolio.show(5) \n",
    "\n",
    "# Define a custom function to estimate statistic of interest\n",
    "\n",
    "def custom_function(df, col_X, col_Y):\n",
    "    var_X = df.agg(F.variance(col_X)).collect()[0][0]\n",
    "    var_Y = df.agg(F.variance(col_Y)).collect()[0][0]\n",
    "    cov_X_Y = df.stat.cov(col_X,col_Y)\n",
    "    result = ((var_Y-cov_X_Y))/( var_X+ var_Y -2 * cov_X_Y)\n",
    "    return result\n",
    "\n",
    "# Initial parameters for Ordinary NonParametric Bootstrap \n",
    "\n",
    "boot_n = 100\n",
    "left_quantile_fraction = 2.5\n",
    "right_quantile_fraction = 97.5\n",
    "\n",
    "# Ordinary NonParametric Bootsrap output \n",
    "\n",
    "results = np.zeros([boot_n])\n",
    "for i in range(0, boot_n):\n",
    "    df_tmp = Portfolio.sample(withReplacement = True, fraction=1.0)\n",
    "    results[i] = custom_function(df_tmp, 'X', 'Y')\n",
    "print('estimated bootstrap lower and upper quantiles = {}'.format(np.percentile(results, [left_quantile_fraction, right_quantile_fraction])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated non-parametric Bootsrap 95% confidence intervals for the estimated regression model parameters:\n",
      "[[-0.17025546 -0.17025546]\n",
      " [40.84756209 40.84756209]]\n"
     ]
    }
   ],
   "source": [
    "## -> Estimate confidence interval for regression parameters using nonparametric Bootstrap\n",
    "\n",
    "# -> Prepare data\n",
    "\n",
    "data = utils.prepare_data(Auto,\n",
    "                    labelCol = 'mpg',\n",
    "                    label_is_categorical = False,\n",
    "                    categoricalCols = [],\n",
    "                    continuousCols = ['horsepower'])\n",
    "\n",
    "# -> Describe the model\n",
    "\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol='label')\n",
    "\n",
    "# -> Bootstrap CI estimates \n",
    "\n",
    "def bootstrap_confidence_intervals(df, model, boot_n, lower_quantile, upper_quantile, sample_prop_data=0.5, seed=42):\n",
    "    results = []\n",
    "    for i in range(0, boot_n):\n",
    "        data_tmp = df.sample(withReplacement = True, fraction=sample_prop_data, seed=seed)\n",
    "        model_fit = model.fit(data_tmp)\n",
    "        result = np.append(model_fit.coefficients.toArray(), model_fit.intercept)\n",
    "        results.append(result)\n",
    "    estim_percentiles = np.apply_along_axis(lambda x: np.percentile(x, [lower_quantile, upper_quantile]),0,results).T\n",
    "    return estim_percentiles\n",
    "\n",
    "boostrap_CI = bootstrap_confidence_intervals(df=data, \n",
    "                                             model=model, \n",
    "                                             boot_n=50, \n",
    "                                             lower_quantile=2.5,\n",
    "                                             upper_quantile=97.5)\n",
    "print('Estimated non-parametric Bootsrap 95% confidence intervals for the estimated regression model parameters:')\n",
    "print(boostrap_CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
